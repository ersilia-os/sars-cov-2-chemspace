{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import rdkit\n",
    "from standardiser import standardise\n",
    "from rdkit import RDLogger\n",
    "import shutil\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "data_dir = os.path.join(\"..\", \"data\")\n",
    "np_dir = os.path.join(data_dir, \"original\", \"NP\")\n",
    "sd_dir = os.path.join(data_dir, \"original\", \"SD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data curation\n",
    "The NP and SD folders contain duplicated and incorrect SMILES.\n",
    "\n",
    "We will use the sd and np PCA files to extract the correct names and apply them to sort the folders into NP_curated and SD_curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 121) 626 626\n",
      "(656, 121) 656 656\n",
      "626 656\n"
     ]
    }
   ],
   "source": [
    "np = pd.read_csv(os.path.join(data_dir, \"original\", \"PCA\", \"np_pca_cleaned.csv\"))\n",
    "sd = pd.read_csv(os.path.join(data_dir, \"original\", \"PCA\", \"sd_pca_cleaned.csv\"))\n",
    "\n",
    "np_names = [name.replace('.****', '').replace('.mol', '') for name in np[\"Title\"]]\n",
    "\n",
    "sd_names = [name.replace('.****', '').replace('.mol', '') for name in sd[\"Title\"]]\n",
    "\n",
    "print(np.shape, len(np_names), len(set(np_names)))\n",
    "print(sd.shape, len(sd_names), len(set(sd_names)))\n",
    "print(len(set(np_names)-set(sd_names)), len(set(sd_names)-set(np_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626 617 617\n"
     ]
    }
   ],
   "source": [
    "source_folder = os.path.join(data_dir, \"original\", 'NP')\n",
    "destination_folder = os.path.join(data_dir, \"original\", 'NP_curated')\n",
    "correct_files = []\n",
    "for file_name in os.listdir(source_folder):\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    if base_name in np_names:\n",
    "        correct_files.append(base_name)\n",
    "        source_path = os.path.join(source_folder, file_name)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "num_files = len(os.listdir(destination_folder))\n",
    "\n",
    "print(len(np_names),len(correct_files), num_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ancistrotanzanine-C',\n",
       " '26,27-Dinorergosta-5,23-dien-3-ol,(3beta)',\n",
       " 'Jubanine H',\n",
       " 'Cryptobeilic-acid-C',\n",
       " '26,27-Dinorergost-5-ene-3,24-diol,(3beta)',\n",
       " 'J02_12-E',\n",
       " 'Androstan-17-one,3-ethyl-3-hydroxy,(5alpha)',\n",
       " '162727',\n",
       " 'Annonidine-F',\n",
       " 'J02_12-Z']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_missing = list(set(np_names)-set(correct_files))\n",
    "np_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ancistrotanzanine C\n",
      "26,27-Dinorergosta-5,23-dien-3-ol,(3.beta)\n",
      "Cryptobeilic acid C\n",
      "26,27-Dinorergost-5-ene-3,24-diol,(3.beta)\n",
      "J02_12_E\n",
      "Androstan-17-one, 3-ethyl-3-hydroxy,(5alpha)\n",
      "Annonidine F\n",
      "J02_12_Z\n",
      "Jubanine B\n",
      "MCSJ37_0012\n",
      "626 626\n"
     ]
    }
   ],
   "source": [
    "name_changes = {'Ancistrotanzanine-C': 'Ancistrotanzanine C',\n",
    " '26,27-Dinorergosta-5,23-dien-3-ol,(3beta)':'26,27-Dinorergosta-5,23-dien-3-ol,(3.beta)',\n",
    " 'Cryptobeilic-acid-C':'Cryptobeilic acid C',\n",
    " '26,27-Dinorergost-5-ene-3,24-diol,(3beta)':'26,27-Dinorergost-5-ene-3,24-diol,(3.beta)',\n",
    " 'J02_12-E':'J02_12_E',\n",
    " 'Androstan-17-one,3-ethyl-3-hydroxy,(5alpha)':'Androstan-17-one, 3-ethyl-3-hydroxy,(5alpha)',\n",
    " 'Annonidine-F':'Annonidine F',\n",
    " 'J02_12-Z':'J02_12_Z',\n",
    " 'Jubanine H': 'Jubanine B', \n",
    " '162727': 'MCSJ37_0012'}\n",
    "\n",
    "source_folder = os.path.join(data_dir, \"original\", 'NP')\n",
    "destination_folder = os.path.join(data_dir, \"original\", 'NP_curated')\n",
    "for k,v in name_changes.items():\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        if base_name in v:\n",
    "            print(base_name)\n",
    "            source_path = os.path.join(source_folder, file_name)\n",
    "            destination_path = os.path.join(destination_folder, file_name)\n",
    "            shutil.copy2(source_path, destination_path)\n",
    "    num_files = len(os.listdir(destination_folder))\n",
    "\n",
    "print(len(np_names), num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate files found:\n",
      "Base name: MCSJ49_0002 - Files: MCSJ49_0002.sdf, MCSJ49_0002.mol\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "directory_path = os.path.join(data_dir, \"original\", 'NP_curated')\n",
    "file_dict = defaultdict(list)\n",
    "for filename in os.listdir(directory_path):\n",
    "    base_name = filename.replace('.mol', '').replace('.sdf', '').replace('.mol2', '')\n",
    "    file_dict[base_name].append(filename)\n",
    "duplicates = {key: value for key, value in file_dict.items() if len(value) > 1}\n",
    "if duplicates:\n",
    "    print(\"Duplicate files found:\")\n",
    "    for base_name, files in duplicates.items():\n",
    "        print(f\"Base name: {base_name} - Files: {', '.join(files)}\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "#manually delete the .sdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656 653 653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Orotic-acid',\n",
       " 'Taribavirin-Hydrochloride',\n",
       " 'LY411575',\n",
       " 'Chloramphenicol-succinate']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "source_folder = os.path.join(data_dir, \"original\", 'SD')\n",
    "destination_folder = os.path.join(data_dir, \"original\", 'SD_curated')\n",
    "correct_files = []\n",
    "for file_name in os.listdir(source_folder):\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    if base_name in sd_names:\n",
    "        correct_files.append(base_name)\n",
    "        source_path = os.path.join(source_folder, file_name)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "num_files = len(os.listdir(destination_folder))\n",
    "\n",
    "print(len(sd_names),len(correct_files), num_files)\n",
    "sd_missing = list(set(sd_names)-set(correct_files))\n",
    "sd_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orotic acid\n",
      "Taribavirin Hydrochloride\n",
      "LY411575 \n",
      "Chloramphenicol succinate\n",
      "656 657\n"
     ]
    }
   ],
   "source": [
    "not_found = []\n",
    "name_changes = {'Orotic-acid': 'Orotic acid',\n",
    " 'Taribavirin-Hydrochloride': 'Taribavirin Hydrochloride',\n",
    " 'LY411575':'LY411575 ',\n",
    " 'Chloramphenicol-succinate':'Chloramphenicol succinate'}\n",
    "\n",
    "source_folder = os.path.join(data_dir, \"original\", 'SD')\n",
    "destination_folder = os.path.join(data_dir, \"original\", 'SD_curated')\n",
    "for k,v in name_changes.items():\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        if base_name in v:\n",
    "            print(base_name)\n",
    "            source_path = os.path.join(source_folder, file_name)\n",
    "            destination_path = os.path.join(destination_folder, file_name)\n",
    "            shutil.copy2(source_path, destination_path)\n",
    "    num_files = len(os.listdir(destination_folder))\n",
    "\n",
    "print(len(sd_names), num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate files found:\n",
      "Base name: SA5_0007 - Files: SA5_0007.sdf, SA5_0007.mol\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "directory_path = os.path.join(data_dir, \"original\", 'SD_curated')\n",
    "file_dict = defaultdict(list)\n",
    "for filename in os.listdir(directory_path):\n",
    "    base_name = filename.replace('.mol', '').replace('.sdf', '').replace('.mol2', '')\n",
    "    file_dict[base_name].append(filename)\n",
    "duplicates = {key: value for key, value in file_dict.items() if len(value) > 1}\n",
    "if duplicates:\n",
    "    print(\"Duplicate files found:\")\n",
    "    for base_name, files in duplicates.items():\n",
    "        print(f\"Base name: {base_name} - Files: {', '.join(files)}\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n",
    "\n",
    "#manually delete the .sdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626 656\n"
     ]
    }
   ],
   "source": [
    "# FINAL Check\n",
    "np_files = len(os.listdir(os.path.join(data_dir, \"original\", 'NP_curated')))\n",
    "sd_files = len(os.listdir(os.path.join(data_dir, \"original\", 'SD_curated')))\n",
    "\n",
    "print(np_files, sd_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/07/24 12:44:29 standardiser.neutralise WARNING] zwitterion with more negative charges than quaternary positive centres detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-standardized molecules (skipped) 90\n",
      "Number of non-standardized molecules (skipped) 159\n"
     ]
    }
   ],
   "source": [
    "def molecule_loader(subfolder):\n",
    "    sdf_paths = []\n",
    "    mol_paths = []\n",
    "    mol2_paths = []\n",
    "    names = []\n",
    "    for fn in os.listdir(subfolder):\n",
    "        if fn.endswith(\".sdf\"):\n",
    "            sdf_paths.append(os.path.join(subfolder, fn))\n",
    "            names += [fn[:-4]]\n",
    "        if fn.endswith(\".mol\"):\n",
    "            mol_paths.append(os.path.join(subfolder, fn))\n",
    "            names += [fn[:-4]]\n",
    "        if fn.endswith(\".mol2\"):\n",
    "            mol2_paths.append(os.path.join(subfolder, fn))\n",
    "            names += [fn[:-5]]\n",
    "    mols = []\n",
    "    for sdf_path in sdf_paths:\n",
    "        mols.append(rdkit.Chem.SDMolSupplier(sdf_path))\n",
    "    for mol_path in mol_paths:\n",
    "        mols.append(rdkit.Chem.MolFromMolFile(mol_path))\n",
    "    for mol2_path in mol2_paths:\n",
    "        mols.append(rdkit.Chem.MolFromMol2File(mol2_path))\n",
    "    mols_ = []\n",
    "    c = 0\n",
    "    for i, mol in enumerate(mols):\n",
    "        try:\n",
    "            mol = standardise.run(mol)\n",
    "            if mol is not None:\n",
    "                mols_ += [(names[i], mol)]\n",
    "        except:\n",
    "            c += 1\n",
    "            continue\n",
    "    print(\"Number of non-standardized molecules (skipped) {0}\".format(c))\n",
    "    return mols_\n",
    "\n",
    "\n",
    "np_mols = molecule_loader(np_dir)\n",
    "sd_mols = molecule_loader(sd_dir)\n",
    "\n",
    "\n",
    "def mols_to_table(mols, category):\n",
    "    mols_ = []\n",
    "    for name, mol in mols:\n",
    "        mols_ += [\n",
    "            (name, rdkit.Chem.MolToInchiKey(mol), rdkit.Chem.MolToSmiles(mol), category)\n",
    "        ]\n",
    "    df = pd.DataFrame(mols_, columns=[\"file_name\", \"inchikey\", \"smiles\", \"category\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "np_df = mols_to_table(np_mols, \"natural\")\n",
    "sd_df = mols_to_table(sd_mols, \"synthetic\")\n",
    "\n",
    "df = pd.concat([np_df, sd_df]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(data_dir, \"all_molecules.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chempfn-paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
